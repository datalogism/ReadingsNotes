# Workshop on Ten Years of BabelNet and Multilingual Neurosymbolic Natural Language Understanding

http://mousse-project.org/events/event-a5f3r5.html


## PROGRAMME

### DAY 1 

* Ten Years of BabelNet: Opening - Roberto Navigli
* Lexicography in the Age of Concept - Simon Krek X
* Progress in defining NLU in specifically reading comprehension "skills" - Anna ROgers X
* BabelNet and Discourse Semantics - Bonnie Webber
* ID10M: Idiom Identification in 10 Languages
* Large Language Models: Will they keep getting bigger? And, how will we use them if they do? - Luke Zettlemoyer X
* Probing for Predicate Argument Structures in Pretrained Language Models - Simone Conia
* Redesigning WSD with Extractive Sense Comprehension and Continuous Sense Comprehension - Edoardo Barba
* On the complementarity of neural and symbolic approaches, and on how to transfer between them - Eduard Hovy
* What do neural vs neurosymbolic models learn? - Hinrich Schütze

### DAY 2 

* Summary of the first day - Roberto Navigli
* Neurosymbolic semantic parsing - Alexander Koller
* Distilling conceptual knowledge from BERT - Steven Schockaert
* REBEL: Relation Extraction By End-to-end Language generation - Pere-Lluís Huguet Cabot
* Unifying verb-based resources into an event-type ontology -Jan Hajič
* Wrap-up and closing session - Roberto Navigli

--- 

## DAY 1

### 1. Lexicography in the Age of Concept - Simon Krek

* Linguistic LOD Cloud 
* UE investment on project
* Word Atlas > Babel will integrate new dictionnary : classicals (Larousse for ex.) and specialized (UMLS/HCtop)
* A network of linked synset
* Could be used for following tasks :
  * Multi entity disambiguation
  * Semantic role labelling
  * Commonsense mining
  * Reasoning
 Language independent => Umberto Eco Blackwell and the perfect language
 
 => Lexicography impossible mission : defining word sens
 
 Exemple of the synset of Love 
 How to anotating meaning from text ? 


### 2. Multilingual Neurosymbolic NLU  - Anna Rogers

* We are living a NLP evaluation crisis : exemple of benchmark of QA task
* How to define a NLP task for human ?

> " Wikitionnary have a wired view on things"

### 3. Large Language Models: Will they keep getting bigger? And, how will we use them if they do? - Luke Zettlemoyer

=> The Sparsely Gated mixt of experts
Modular language models
domain expert mixture

* Linguistic data are heterogeneous : news / medical / fiction .... 

Papers around it :
https://arxiv.org/pdf/2103.16716.pdf
https://openreview.net/forum?id=BqgeyEMB-5
